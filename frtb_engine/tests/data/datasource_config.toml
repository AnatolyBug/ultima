title = "setup.toml Example"
type = "CSV"

# first file path 
# "C:/rust/DeltaGirr100_100_400000.csv"
# "C:/rust/ultima/frtb_engine/tests/data/Delta.csv"
# "C:/rust/SensEq.csv"
# "C:/rust/VegaEq.csv"
# "C:/rust/DeltaCSR.csv"
# "C:/rust/drc.csv"
files = ["C:/rust/ultima/frtb_engine/tests/data/Delta.csv"]
# trade attributes
# "C:/rust/TradeAttributes2.csv"
#"C:/rust/ultima/frtb_engine/tests/data/TradeAttributes.csv"
attributes_path = "C:/rust/ultima/frtb_engine/tests/data/TradeAttributes.csv"
# HMS
hierarchy_path = "C:/rust/ultima/frtb_engine/tests/data/hms.csv"
# file_1/file_2/file_3 <-> trade attributes
files_join_attributes = ["TradeId"]
# attributes <-> hierarchy
# must be provided if hierarchy file is provided
attributes_join_hierarchy = ["BookId"] 
# Measure columns. Optional field. Used as a constraint on which numeric columns
# can be aggregated eg ("SensitivitySpot", _)
# f1_measure_cols=[]
# Polars can't always guess the right type of col. eg an empty col is str
# So one must provide the list
f1_numeric_cols = ["GrossJTD", "PnL_Up", "PnL_Down", "SensitivitySpot", "Sensitivity_025Y","Sensitivity_05Y",
"Sensitivity_1Y","Sensitivity_2Y","Sensitivity_3Y","Sensitivity_5Y",
"Sensitivity_10Y","Sensitivity_15Y","Sensitivity_20Y","Sensitivity_30Y",]
# Columns which must be cast to str in the preprocessing step
f1_cast_to_str = ["BucketBCBS", "RiskFactor", "RiskFactorType", "GirrVegaUnderlyingMaturity", "MaturityDate", "COB"]
# Build Params. Optional additional parameters to be passed to DataSet.prepare() and can be used in .build() as well
# csrnonsec_covered_bond_15 = "true" <-> column CoveredBondReducedWeight must be provided
[build_params]
fx_sqrt2_div = "true"
girr_sqrt2_div = "true"
csrnonsec_covered_bond_15 = "true"
offshore_onshore_fx = "{\"THO\": \"THB\", \"CNO\": \"CNY\"}"
DayCountConvention = "2"
DateFormat = "%d/%m/%Y"